{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train 3.7822/0.0756 | Val 3.3454/0.1422\n",
      "Epoch 2: Train 3.1482/0.1560 | Val 3.0401/0.1778\n",
      "Epoch 3: Train 2.9061/0.2096 | Val 3.3838/0.2356\n",
      "Epoch 4: Train 2.6845/0.2559 | Val 2.6246/0.2711\n",
      "Epoch 5: Train 2.3745/0.3257 | Val 2.4049/0.3267\n",
      "Epoch 6: Train 2.1149/0.3923 | Val 2.2974/0.3489\n",
      "Epoch 7: Train 1.9028/0.4406 | Val 1.7976/0.4711\n",
      "Epoch 8: Train 1.7324/0.4861 | Val 1.6680/0.4933\n",
      "Epoch 9: Train 1.6036/0.5210 | Val 1.6275/0.5356\n",
      "Epoch 10: Train 1.4929/0.5487 | Val 1.4649/0.5311\n",
      "Epoch 11: Train 1.4208/0.5705 | Val 1.5268/0.5533\n",
      "Epoch 12: Train 1.3423/0.5905 | Val 1.5081/0.5578\n",
      "Epoch 13: Train 1.2804/0.6082 | Val 1.2821/0.6200\n",
      "Epoch 14: Train 1.2315/0.6225 | Val 1.6187/0.5578\n",
      "Epoch 15: Train 1.1938/0.6315 | Val 1.2918/0.6267\n",
      "Epoch 16: Train 1.1454/0.6446 | Val 1.3201/0.5822\n",
      "Epoch 17: Train 1.1127/0.6535 | Val 1.3411/0.5911\n",
      "Epoch 18: Train 1.0890/0.6608 | Val 1.3062/0.5978\n",
      "Epoch 19: Train 1.0589/0.6675 | Val 1.2375/0.6089\n",
      "Epoch 20: Train 1.0343/0.6767 | Val 1.3187/0.5956\n",
      "Epoch 21: Train 1.0188/0.6798 | Val 1.2358/0.6244\n",
      "Epoch 22: Train 0.9890/0.6884 | Val 1.2754/0.5867\n",
      "Epoch 23: Train 0.9801/0.6920 | Val 1.1812/0.6578\n",
      "Epoch 24: Train 0.9588/0.6967 | Val 1.2703/0.6200\n",
      "Epoch 25: Train 0.9454/0.7003 | Val 1.3050/0.5844\n",
      "Epoch 26: Train 0.9342/0.7017 | Val 1.1808/0.6378\n",
      "Epoch 27: Train 0.9171/0.7086 | Val 1.2215/0.6422\n",
      "Epoch 28: Train 0.9063/0.7126 | Val 1.3180/0.6267\n",
      "Epoch 29: Train 0.8921/0.7153 | Val 1.3772/0.6156\n",
      "Epoch 30: Train 0.8834/0.7174 | Val 1.2998/0.6000\n",
      "Epoch 31: Train 0.8735/0.7212 | Val 1.2975/0.6133\n",
      "Epoch 32: Train 0.8576/0.7253 | Val 1.2705/0.6356\n",
      "Epoch 33: Train 0.8494/0.7290 | Val 1.2252/0.6578\n",
      "Epoch 34: Train 0.8391/0.7307 | Val 1.2490/0.6267\n",
      "Epoch 35: Train 0.8308/0.7346 | Val 1.3564/0.6422\n",
      "Epoch 36: Train 0.8239/0.7364 | Val 1.3526/0.6044\n",
      "Epoch 37: Train 0.8205/0.7349 | Val 1.3539/0.6267\n",
      "Epoch 38: Train 0.8169/0.7376 | Val 1.3251/0.6111\n",
      "Epoch 39: Train 0.8026/0.7404 | Val 1.2911/0.6089\n",
      "Epoch 40: Train 0.7888/0.7460 | Val 1.3025/0.6244\n",
      "Epoch 41: Train 0.7897/0.7451 | Val 1.3005/0.6333\n",
      "Epoch 42: Train 0.7766/0.7492 | Val 1.2567/0.6089\n",
      "Epoch 43: Train 0.7763/0.7498 | Val 1.2341/0.6511\n",
      "Epoch 44: Train 0.7711/0.7510 | Val 1.2965/0.6022\n",
      "Epoch 45: Train 0.7648/0.7537 | Val 1.2473/0.6178\n",
      "Epoch 46: Train 0.7553/0.7558 | Val 1.3279/0.6178\n",
      "Epoch 47: Train 0.7605/0.7535 | Val 1.3605/0.6356\n",
      "Epoch 48: Train 0.7493/0.7566 | Val 1.2549/0.6222\n",
      "Epoch 49: Train 0.7440/0.7591 | Val 1.2730/0.6444\n",
      "Epoch 50: Train 0.7384/0.7605 | Val 1.3985/0.6200\n",
      "Epoch 51: Train 0.7371/0.7618 | Val 1.4086/0.5800\n",
      "Epoch 52: Train 0.7286/0.7632 | Val 1.3092/0.6067\n",
      "Epoch 53: Train 0.7340/0.7618 | Val 1.2008/0.6422\n",
      "Epoch 54: Train 0.7265/0.7627 | Val 1.2217/0.6467\n",
      "Epoch 55: Train 0.7268/0.7627 | Val 1.3895/0.6244\n",
      "Epoch 56: Train 0.7102/0.7706 | Val 1.2224/0.6289\n",
      "Epoch 57: Train 0.7174/0.7650 | Val 1.3110/0.6267\n",
      "Epoch 58: Train 0.7081/0.7692 | Val 1.2983/0.6222\n",
      "Epoch 59: Train 0.7119/0.7704 | Val 1.2047/0.6467\n",
      "Epoch 60: Train 0.7082/0.7707 | Val 1.2707/0.6489\n",
      "Epoch 61: Train 0.6946/0.7753 | Val 1.3648/0.6178\n",
      "Epoch 62: Train 0.6920/0.7751 | Val 1.3492/0.6378\n",
      "Epoch 63: Train 0.6901/0.7757 | Val 1.3366/0.6622\n",
      "Epoch 64: Train 0.6934/0.7745 | Val 1.2944/0.6533\n",
      "Epoch 65: Train 0.6880/0.7769 | Val 1.2539/0.6378\n",
      "Epoch 66: Train 0.6877/0.7747 | Val 1.2705/0.6289\n",
      "Epoch 67: Train 0.6829/0.7792 | Val 1.2390/0.6422\n",
      "Epoch 68: Train 0.6856/0.7767 | Val 1.1799/0.6756\n",
      "Epoch 69: Train 0.6762/0.7782 | Val 1.3087/0.5911\n",
      "Epoch 70: Train 0.6686/0.7829 | Val 1.3065/0.6156\n",
      "Epoch 71: Train 0.6790/0.7808 | Val 1.2953/0.6489\n",
      "Epoch 72: Train 0.6754/0.7781 | Val 1.2513/0.6378\n",
      "Epoch 73: Train 0.6629/0.7852 | Val 1.2330/0.6600\n",
      "Epoch 74: Train 0.6687/0.7824 | Val 1.2844/0.6444\n",
      "Epoch 75: Train 0.6570/0.7850 | Val 1.3472/0.6200\n",
      "Epoch 76: Train 0.6598/0.7840 | Val 1.3681/0.6533\n",
      "Epoch 77: Train 0.6587/0.7852 | Val 1.3182/0.6400\n",
      "Epoch 78: Train 0.6587/0.7846 | Val 1.3133/0.6133\n",
      "Epoch 79: Train 0.6623/0.7853 | Val 1.4565/0.6111\n",
      "Epoch 80: Train 0.6560/0.7867 | Val 1.3419/0.6400\n",
      "Epoch 81: Train 0.6502/0.7865 | Val 1.3525/0.6378\n",
      "Epoch 82: Train 0.6588/0.7850 | Val 1.3170/0.6600\n",
      "Epoch 83: Train 0.6500/0.7893 | Val 1.2354/0.6244\n",
      "Epoch 84: Train 0.6462/0.7892 | Val 1.1883/0.6644\n",
      "Epoch 85: Train 0.6466/0.7882 | Val 1.3065/0.6267\n",
      "Epoch 86: Train 0.6408/0.7916 | Val 1.3508/0.6400\n",
      "Epoch 87: Train 0.6420/0.7906 | Val 1.4689/0.5911\n",
      "Epoch 88: Train 0.6434/0.7886 | Val 1.2336/0.6533\n",
      "Epoch 89: Train 0.6439/0.7893 | Val 1.2413/0.6467\n",
      "Epoch 90: Train 0.6366/0.7913 | Val 1.3299/0.6444\n",
      "Best validation acc: 0.6756\n",
      "RGB: 0.6600\n",
      "RG: 0.6444\n",
      "RB: 0.6422\n",
      "GB: 0.6244\n",
      "R: 0.5622\n",
      "G: 0.5644\n",
      "B: 0.5578\n",
      "=== Training & Validation ===\n",
      " epoch  train_loss  train_acc  val_loss  val_acc\n",
      "     1    3.782164   0.075578  3.345406 0.142222\n",
      "     2    3.148170   0.155957  3.040111 0.177778\n",
      "     3    2.906120   0.209633  3.383772 0.235556\n",
      "     4    2.684479   0.255918  2.624563 0.271111\n",
      "     5    2.374505   0.325701  2.404861 0.326667\n",
      "     6    2.114937   0.392294  2.297387 0.348889\n",
      "     7    1.902799   0.440600  1.797607 0.471111\n",
      "     8    1.732353   0.486127  1.667951 0.493333\n",
      "     9    1.603625   0.521011  1.627471 0.535556\n",
      "    10    1.492875   0.548709  1.464887 0.531111\n",
      "    11    1.420833   0.570517  1.526794 0.553333\n",
      "    12    1.342312   0.590525  1.508053 0.557778\n",
      "    13    1.280407   0.608196  1.282101 0.620000\n",
      "    14    1.231520   0.622503  1.618736 0.557778\n",
      "    15    1.193762   0.631536  1.291839 0.626667\n",
      "    16    1.145399   0.644564  1.320072 0.582222\n",
      "    17    1.112741   0.653454  1.341091 0.591111\n",
      "    18    1.088988   0.660845  1.306242 0.597778\n",
      "    19    1.058910   0.667462  1.237452 0.608889\n",
      "    20    1.034289   0.676731  1.318670 0.595556\n",
      "    21    1.018792   0.679779  1.235840 0.624444\n",
      "    22    0.989022   0.688385  1.275436 0.586667\n",
      "    23    0.980079   0.691954  1.181191 0.657778\n",
      "    24    0.958810   0.696692  1.270255 0.620000\n",
      "    25    0.945438   0.700324  1.305013 0.584444\n",
      "    26    0.934200   0.701650  1.180787 0.637778\n",
      "    27    0.917141   0.708630  1.221461 0.642222\n",
      "    28    0.906322   0.712562  1.317976 0.626667\n",
      "    29    0.892072   0.715278  1.377168 0.615556\n",
      "    30    0.883377   0.717379  1.299750 0.600000\n",
      "    31    0.873451   0.721216  1.297453 0.613333\n",
      "    32    0.857597   0.725306  1.270520 0.635556\n",
      "    33    0.849356   0.729001  1.225152 0.657778\n",
      "    34    0.839085   0.730691  1.249021 0.626667\n",
      "    35    0.830808   0.734576  1.356436 0.642222\n",
      "    36    0.823939   0.736376  1.352567 0.604444\n",
      "    37    0.820542   0.734860  1.353896 0.626667\n",
      "    38    0.816897   0.737623  1.325110 0.611111\n",
      "    39    0.802649   0.740371  1.291090 0.608889\n",
      "    40    0.788829   0.746009  1.302507 0.624444\n",
      "    41    0.789673   0.745093  1.300528 0.633333\n",
      "    42    0.776554   0.749183  1.256738 0.608889\n",
      "    43    0.776296   0.749767  1.234075 0.651111\n",
      "    44    0.771055   0.751046  1.296457 0.602222\n",
      "    45    0.764838   0.753683  1.247306 0.617778\n",
      "    46    0.755290   0.755815  1.327936 0.617778\n",
      "    47    0.760534   0.753478  1.360516 0.635556\n",
      "    48    0.749324   0.756621  1.254862 0.622222\n",
      "    49    0.743959   0.759084  1.272955 0.644444\n",
      "    50    0.738400   0.760505  1.398452 0.620000\n",
      "    51    0.737085   0.761784  1.408587 0.580000\n",
      "    52    0.728640   0.763237  1.309210 0.606667\n",
      "    53    0.733950   0.761832  1.200841 0.642222\n",
      "    54    0.726541   0.762732  1.221715 0.646667\n",
      "    55    0.726807   0.762669  1.389544 0.624444\n",
      "    56    0.710167   0.770612  1.222427 0.628889\n",
      "    57    0.717376   0.765022  1.310999 0.626667\n",
      "    58    0.708056   0.769206  1.298296 0.622222\n",
      "    59    0.711944   0.770391  1.204710 0.646667\n",
      "    60    0.708206   0.770722  1.270669 0.648889\n",
      "    61    0.694642   0.775286  1.364774 0.617778\n",
      "    62    0.692042   0.775065  1.349213 0.637778\n",
      "    63    0.690138   0.775697  1.336550 0.662222\n",
      "    64    0.693438   0.774512  1.294446 0.653333\n",
      "    65    0.687996   0.776913  1.253927 0.637778\n",
      "    66    0.687720   0.774670  1.270462 0.628889\n",
      "    67    0.682851   0.779234  1.239012 0.642222\n",
      "    68    0.685614   0.776660  1.179885 0.675556\n",
      "    69    0.676187   0.778208  1.308747 0.591111\n",
      "    70    0.668591   0.782945  1.306550 0.615556\n",
      "    71    0.679021   0.780797  1.295299 0.648889\n",
      "    72    0.675359   0.778144  1.251257 0.637778\n",
      "    73    0.662916   0.785156  1.233009 0.660000\n",
      "    74    0.668702   0.782408  1.284354 0.644444\n",
      "    75    0.657046   0.784951  1.347245 0.620000\n",
      "    76    0.659790   0.784003  1.368078 0.653333\n",
      "    77    0.658710   0.785172  1.318208 0.640000\n",
      "    78    0.658709   0.784603  1.313276 0.613333\n",
      "    79    0.662289   0.785345  1.456451 0.611111\n",
      "    80    0.656031   0.786704  1.341926 0.640000\n",
      "    81    0.650249   0.786530  1.352488 0.637778\n",
      "    82    0.658754   0.784982  1.316983 0.660000\n",
      "    83    0.650029   0.789278  1.235373 0.624444\n",
      "    84    0.646191   0.789151  1.188335 0.664444\n",
      "    85    0.646605   0.788156  1.306495 0.626667\n",
      "    86    0.640839   0.791583  1.350792 0.640000\n",
      "    87    0.642000   0.790557  1.468875 0.591111\n",
      "    88    0.643437   0.788598  1.233614 0.653333\n",
      "    89    0.643922   0.789293  1.241317 0.646667\n",
      "    90    0.636611   0.791315  1.329923 0.644444\n",
      "\n",
      "=== Channel Accuracy ===\n",
      "channel_combo  accuracy\n",
      "          RGB  0.660000\n",
      "           RG  0.644444\n",
      "           RB  0.642222\n",
      "           GB  0.624444\n",
      "            R  0.562222\n",
      "            G  0.564444\n",
      "            B  0.557778\n",
      "\n",
      "=== Model Complexity (ptflops) ===\n",
      "請先安裝 ptflops：pip install ptflops\n",
      "\n",
      "=== Model Complexity (thop) ===\n",
      "THOP Params: 32,817,717.0  FLOPs: 162,745,676.0\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 改進後的動態 ResNet18 模型訓練與多通道推論\n",
    "# 此 Notebook 實現：\n",
    "# 1. 使用同資料夾中的 images 與 txt 文件（train.txt、val.txt、test.txt）建立自訂 Dataset  \n",
    "# 2. 定義改進後的動態卷積及動態 ResNet18 模型  \n",
    "#    - 延緩溫度退火：初始溫度設為 31，每個 epoch 降 1（最低保持 1）  \n",
    "#    - 在全連接層前加入 Dropout (p=0.1)  \n",
    "# 3. 訓練過程中存下每個 epoch 的訓練與驗證結果  \n",
    "# 4. 訓練後對測試集進行各種通道組合（RGB, RG, RB, GB, R, G, B）下的推論，結果存檔  \n",
    "# 5. 訓練結束後顯示論文表格：包含訓練/驗證曲線、通道推論結果，以及模型參數與 FLOPS  \n",
    "\n",
    "# %% [code]\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. 自訂 Dataset 讀取 txt 文件  \n",
    "# 每行格式：\"images/xxx.JPEG label\"\n",
    "\n",
    "# %% [code]\n",
    "class TxtImageDataset(Dataset):\n",
    "    def __init__(self, txt_file, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line: continue\n",
    "                path, label = line.split()\n",
    "                self.samples.append((path, int(label)))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        full_path = os.path.join(self.root_dir, img_path)\n",
    "        image = Image.open(full_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. 定義動態卷積模組及改進後的動態 ResNet18 模型\n",
    "\n",
    "# %% [code]\n",
    "class attention2d(nn.Module):\n",
    "    def __init__(self, in_planes, ratio, K, temperature, init_weight=True):\n",
    "        super(attention2d, self).__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        hidden_planes = int(in_planes * ratio) + 1 if in_planes != 3 else K\n",
    "        self.fc1 = nn.Conv2d(in_planes, hidden_planes, kernel_size=1, bias=False)\n",
    "        self.fc2 = nn.Conv2d(hidden_planes, K, kernel_size=1, bias=True)\n",
    "        self.temperature = temperature\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    def update_temperature(self):\n",
    "        if self.temperature > 1:\n",
    "            self.temperature -= 1\n",
    "            if self.temperature < 1:\n",
    "                self.temperature = 1\n",
    "            print(f\"Attention temperature -> {self.temperature}\")\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x).view(x.size(0), -1)\n",
    "        return F.softmax(x / self.temperature, dim=1)\n",
    "\n",
    "class Dynamic_conv2d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, ratio=0.25, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True, K=4, temperature=31, init_weight=True):\n",
    "        super(Dynamic_conv2d, self).__init__()\n",
    "        assert in_planes % groups == 0\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.K = K\n",
    "        self.attention = attention2d(in_planes, ratio, K, temperature)\n",
    "        self.weight = nn.Parameter(torch.randn(K, out_planes, in_planes // groups, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(K, out_planes)) if bias else None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i], mode='fan_in', nonlinearity='relu')\n",
    "    def update_temperature(self):\n",
    "        self.attention.update_temperature()\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        att = self.attention(x)  # [B, K]\n",
    "        x_flat = x.view(1, B*C, H, W)\n",
    "        w_flat = self.weight.view(self.K, -1)\n",
    "        agg_w = torch.mm(att, w_flat).view(B * self.out_planes, C // self.groups, self.kernel_size, self.kernel_size)\n",
    "        if self.bias is not None:\n",
    "            agg_b = torch.mm(att, self.bias).view(-1)\n",
    "            out = F.conv2d(x_flat, agg_w, bias=agg_b,\n",
    "                           stride=self.stride, padding=self.padding,\n",
    "                           dilation=self.dilation, groups=self.groups * B)\n",
    "        else:\n",
    "            out = F.conv2d(x_flat, agg_w, bias=None,\n",
    "                           stride=self.stride, padding=self.padding,\n",
    "                           dilation=self.dilation, groups=self.groups * B)\n",
    "        return out.view(B, self.out_planes, out.size(-2), out.size(-1))\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                          padding=1, bias=False)\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        norm_layer = norm_layer or nn.BatchNorm2d\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(3, 2, 1)\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "        layers = [block(self.inplanes, planes, stride, downsample, norm_layer)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, norm_layer=norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "    def update_temperature(self):\n",
    "        for child in self.children():\n",
    "            if hasattr(child, \"update_temperature\"):\n",
    "                child.update_temperature()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x); x = self.layer2(x)\n",
    "        x = self.layer3(x); x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "def dy_resnet18(num_classes):\n",
    "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. 數據預處理與 DataLoader 設定\n",
    "\n",
    "# %% [code]\n",
    "data_root = \".\"\n",
    "train_txt = os.path.join(data_root, \"train.txt\")\n",
    "val_txt   = os.path.join(data_root, \"val.txt\")\n",
    "test_txt  = os.path.join(data_root, \"test.txt\")\n",
    "img_root  = os.path.join(data_root)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset = TxtImageDataset(train_txt, root_dir=img_root, transform=train_transform)\n",
    "val_dataset   = TxtImageDataset(val_txt,   root_dir=img_root, transform=eval_transform)\n",
    "test_dataset  = TxtImageDataset(test_txt,  root_dir=img_root, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,  num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. 訓練與驗證函數 & 訓練迴圈\n",
    "\n",
    "# %% [code]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = dy_resnet18(num_classes=len(train_dataset.samples)).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "num_epochs = 90\n",
    "\n",
    "with open(\"training_results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        for i in range(imgs.size(0)):\n",
    "            if random.random() < 0.5:\n",
    "                drop_n = 1 if random.random()<0.67 else 2\n",
    "                for ch in random.sample([0,1,2], drop_n):\n",
    "                    imgs[i,ch] = 0\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        correct += (out.argmax(1) == labels).sum().item()\n",
    "    return total_loss/len(train_loader.dataset), correct/len(train_loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "            total_loss += F.cross_entropy(out, labels, reduction=\"sum\").item()\n",
    "            correct += (out.argmax(1) == labels).sum().item()\n",
    "    return total_loss/len(loader.dataset), correct/len(loader.dataset)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    tr_loss, tr_acc = train_epoch()\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "    print(f\"Epoch {epoch}: Train {tr_loss:.4f}/{tr_acc:.4f} | Val {val_loss:.4f}/{val_acc:.4f}\")\n",
    "    with open(\"training_results.csv\", \"a\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([epoch, tr_loss, tr_acc, val_loss, val_acc])\n",
    "    model.update_temperature()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_dy_resnet18.pth\")\n",
    "print(f\"Best validation acc: {best_val_acc:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. 測試：多通道組合推論\n",
    "\n",
    "# %% [code]\n",
    "def modify_channels(x, combo):\n",
    "    mapping = {\"R\":0, \"G\":1, \"B\":2}\n",
    "    out = torch.zeros_like(x)\n",
    "    for c in combo:\n",
    "        out[:, mapping[c]] = x[:, mapping[c]]\n",
    "    return out\n",
    "\n",
    "combos = [\"RGB\",\"RG\",\"RB\",\"GB\",\"R\",\"G\",\"B\"]\n",
    "results = {c:{\"correct\":0,\"total\":0} for c in combos}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        for combo in combos:\n",
    "            mod = modify_channels(imgs, combo)\n",
    "            out = model(mod)\n",
    "            results[combo][\"correct\"] += (out.argmax(1)==labels).sum().item()\n",
    "            results[combo][\"total\"]   += labels.size(0)\n",
    "\n",
    "with open(\"channel_accuracy_dy.csv\",\"w\",newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"channel_combo\",\"accuracy\"])\n",
    "    for c in combos:\n",
    "        acc = results[c][\"correct\"]/results[c][\"total\"]\n",
    "        writer.writerow([c, acc])\n",
    "        print(f\"{c}: {acc:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. 顯示論文表格結果：Training/Val、Channel Accuracy、Model Complexity\n",
    "\n",
    "# %% [code]\n",
    "print(\"=== Training & Validation ===\")\n",
    "df_tr = pd.read_csv(\"training_results.csv\")\n",
    "print(df_tr.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Channel Accuracy ===\")\n",
    "df_ch = pd.read_csv(\"channel_accuracy_dy.csv\")\n",
    "print(df_ch.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Model Complexity (ptflops) ===\")\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    macs, params = get_model_complexity_info(model, (3,224,224),\n",
    "                                             as_strings=True, print_per_layer_stat=False)\n",
    "    print(f\"Parameters (ptflops): {params}\")\n",
    "    print(f\"FLOPS      (ptflops): {macs}\")\n",
    "except ImportError:\n",
    "    print(\"請先安裝 ptflops：pip install ptflops\")\n",
    "\n",
    "# —— 額外使用 thop 計算 FLOPs 與 Params —— \n",
    "from thop import profile\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "flops, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "print(f\"\\n=== Model Complexity (thop) ===\")\n",
    "print(f\"THOP Params: {params:,}  FLOPs: {flops:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7e5f1-fc5f-4d46-875c-150de44b3341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
